# -*- coding: utf-8 -*-
"""fraudDetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AxtjuC_qGq0ojyTofcafWKL4mqsIAP8L
"""

import seaborn
import pandas as pd
import numpy as np
import codecademylib3
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import codecademylib3

# Load the data
transactions = pd.read_csv('transactions_modified.csv')
print(transactions.head())
print(transactions.info())


# How many fraudulent transactions?
# 0 representing non-fraudulent transaction
# 1 representing a fraudulent transaction
print(transactions['isFraud'].value_counts())

# Summary statistics on amount column
# -> Mean: 537307 and Median: 126530;
# -> Therefore, some transactions are too large.
print(transactions["amount"].describe())

# Create isPayment field
transactions["isPayment"] = 0
transactions.loc[transactions["type"].isin(["PAYMENT", "DEBIT"]), "isPayment"] = 1
print(transactions["isPayment"])
print(transactions['isPayment'].value_counts())

# Create isMovement field
transactions["isMovement"] = 0
transactions.loc[transactions["type"].isin(["CASH_OUT", "TRANSFER"]), "isMovement"] = 1
print(transactions["isMovement"])
print(transactions['isMovement'].value_counts())

# Create accountDiff field
transactions["accountDiff"] = abs(transactions["oldbalanceOrg"] - transactions["oldbalanceDest"])
print(transactions["accountDiff"])

# Create features and label variables
features = transactions[["amount","isPayment","isMovement","accountDiff"]].copy()
label = transactions[["isFraud"]].copy()

print(features)
print(label)

# Split dataset
train_X, test_X, train_y, test_y = train_test_split(features, label, train_size=0.8)

# Normalize the features variables
scaler = StandardScaler()
train_X = scaler.fit_transform(train_X)
test_X = scaler.transform(test_X)

# Fit the model to the training data
model = LogisticRegression()
model.fit(train_X, train_y)

# Score the model on the training data
print(model.score(train_X, train_y))

# Score the model on the test data
print(model.score(test_X, test_y))

# Print the model coefficients
print(model.coef_)
# [[ 2.54648845 -0.60396971  2.13610819 -0.87985453]]
# "amount" > "accountDiff" > "isMovement" > "isPayment"

# New transaction data
transaction1 = np.array([123456.78, 0.0, 1.0, 54670.1])
transaction2 = np.array([98765.43, 1.0, 0.0, 8524.75])
transaction3 = np.array([543678.31, 1.0, 0.0, 510025.5])

# Create a new transaction
my_transaction = np.array([555234567.5, 1.0, 0.0, 55555555.5])

# Combine new transactions into a single array
sample_transactions = np.vstack((transaction1, transaction2, transaction3, my_transaction))
print(sample_transactions)

# Normalize the new transactions
sample_transactions = scaler.transform(sample_transactions)

# Predict fraud on the new transactions
print(model.predict(sample_transactions))

# Show probabilities on the new transactions
print(model.predict_proba(sample_transactions))

# EOF